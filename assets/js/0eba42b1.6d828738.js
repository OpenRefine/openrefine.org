"use strict";(self.webpackChunkOpenRefine_Documentation=self.webpackChunkOpenRefine_Documentation||[]).push([[9811],{80021:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>o,default:()=>c,frontMatter:()=>r,metadata:()=>a,toc:()=>l});var i=t(64861),s=t(69018);const r={id:"clustering-in-depth",title:"Clustering Methods In-depth",sidebar_label:"Clustering methods in-depth"},o="Introduction",a={id:"technical-reference/clustering-in-depth",title:"Clustering Methods In-depth",description:"Methods and theory behind the clustering functionality in OpenRefine.",source:"@site/docs/technical-reference/clustering-in-depth.md",sourceDirName:"technical-reference",slug:"/technical-reference/clustering-in-depth",permalink:"/docs/technical-reference/clustering-in-depth",draft:!1,unlisted:!1,editUrl:"https://github.com/OpenRefine/openrefine.github.com/edit/master/docs/technical-reference/clustering-in-depth.md",tags:[],version:"current",lastUpdatedBy:"Antonin Delpeuch",lastUpdatedAt:1674207315e3,frontMatter:{id:"clustering-in-depth",title:"Clustering Methods In-depth",sidebar_label:"Clustering methods in-depth"},sidebar:"docs",previous:{title:"Architecture in version 4",permalink:"/docs/technical-reference/architecture-4"},next:{title:"OpenRefine API",permalink:"/docs/technical-reference/openrefine-api"}},h={},l=[{value:"Key Collision Methods",id:"key-collision-methods",level:2},{value:"Fingerprint",id:"fingerprint",level:3},{value:"N-Gram Fingerprint",id:"n-gram-fingerprint",level:3},{value:"Phonetic Fingerprint",id:"phonetic-fingerprint",level:3},{value:"Metaphone3",id:"metaphone3",level:4},{value:"Cologne Phonetics",id:"cologne-phonetics",level:4},{value:"Daitch-Moktoff",id:"daitch-moktoff",level:4},{value:"Beider-Morse",id:"beider-morse",level:4},{value:"Nearest Neighbor Methods",id:"nearest-neighbor-methods",level:2},{value:"Levenshtein Distance",id:"levenshtein-distance",level:3},{value:"PPM",id:"ppm",level:3}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"Methods and theory behind the clustering functionality in OpenRefine."})}),"\n",(0,i.jsx)(n.h1,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsxs)(n.p,{children:["In OpenRefine, ",(0,i.jsx)(n.a,{href:"https://docs.openrefine.org/manual/cellediting#cluster-and-edit",children:"clustering"}),' refers to the operation of "finding groups of\ndifferent values that might be alternative representations of the same\nthing."']}),"\n",(0,i.jsxs)(n.p,{children:["It is worth noting that clustering in OpenRefine works only at the\nsyntactic level (the character composition of the cell value) and, while\nvery useful to spot errors, typos, and inconsistencies, it's by no means\nenough to perform effective semantically-aware reconciliation. This is\nwhy OpenRefine uses ",(0,i.jsx)(n.a,{href:"https://docs.openrefine.org/manual/reconciling",children:"external semantically-aware reconciliation services"}),"\n(such as Wikidata) to compensate for the deficiencies of syntax-level\nclustering alone."]}),"\n",(0,i.jsx)(n.h1,{id:"methodologies",children:"Methodologies"}),"\n",(0,i.jsx)(n.p,{children:"To strike a balance between general applicability and\nusefulness, OpenRefine ships with a selected number of clustering\nmethods and algorithms that have proven effective and fast enough to use\nin a wide variety of situations."}),"\n",(0,i.jsx)(n.p,{children:"OpenRefine currently offers 2 broad categories of clustering methods:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Token-based (n-gram, key collision, etc.)"}),"\n",(0,i.jsx)(n.li,{children:"Character-based, also known as Edit distance (Levenshtein distance, PPM, etc.)"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"NOTE:"}),"  Performance differs depending on the strings that you want to cluster in your data which might be short or very long or varying.  String length complexity has a large part to do with the algorithm that might perform faster (but not necessarily better!).  In general, it's usually best to use heavy algorithms for shorter strings that can provide better quality \u2013 like Levenshtein distance.  And token-based algorithms for longer strings such as n-grams (q-grams), bag distance, Jaccard similarity, Dice coefficient, etc. (some of which we do not provide currently)."]}),"\n",(0,i.jsx)(n.h2,{id:"key-collision-methods",children:"Key Collision Methods"}),"\n",(0,i.jsx)(n.p,{children:'"Key Collision" methods are based on the idea of creating an alternative\nrepresentation of a value (a "key") that contains only the most valuable\nor meaningful part of the string and "buckets" (or "bin" as it\'s\ndescribed inside OpenRefine\'s code) together different strings based on\nthe fact that their key is the same (hence the name "key collision").'}),"\n",(0,i.jsx)(n.h3,{id:"fingerprint",children:"Fingerprint"}),"\n",(0,i.jsx)(n.p,{children:"The fingerprinting method is the least likely to produce false\npositives, which is why it is the default method."}),"\n",(0,i.jsx)(n.p,{children:"The process that generates the key from a string value is the following\n(note that the order of these operations is significant):"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"remove leading and trailing whitespace"}),"\n",(0,i.jsx)(n.li,{children:"change all characters to their lowercase representation"}),"\n",(0,i.jsx)(n.li,{children:"remove all punctuation and control characters"}),"\n",(0,i.jsx)(n.li,{children:'normalize extended western characters to their ASCII representation\n(for example "g\xf6del" \u2192 "godel")'}),"\n",(0,i.jsx)(n.li,{children:"split the string into whitespace-separated tokens"}),"\n",(0,i.jsx)(n.li,{children:"sort the tokens and remove duplicates"}),"\n",(0,i.jsx)(n.li,{children:"join the tokens back together"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["If you're curious, the code that performs this is\n",(0,i.jsx)(n.a,{href:"http://github.com/OpenRefine/OpenRefine/blob/master/main/src/com/google/refine/clustering/binning/FingerprintKeyer.java",children:"here"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"Several factors play a role in this fingerprint:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"because whitespace is normalized, characters are lowercased, and\npunctuation is removed, those parts don't play a differentiation\nrole in the fingerprint. Because these attributes of the string are\nthe least significant in terms of meaning differentiation, these\nturn out to be the most varying parts of the strings, and removing\nthem has a substantial benefit in emerging clusters."}),"\n",(0,i.jsx)(n.li,{children:'because the string parts are sorted, the given order of tokens\ndoesn\'t matter (so "Cruise, Tom" and "Tom Cruise" both end up with a\nfingerprint "cruise tom" and therefore end up in the same cluster)'}),"\n",(0,i.jsx)(n.li,{children:'normalizing extended western characters plays the role of\nreproducing data entry mistakes performed when entering extended\ncharacters with an ASCII-only keyboard. Note that this procedure can\nalso lead to false positives. For example, "g\xf6del" and "god\xe9l" would\nboth end up with "godel" as their fingerprint, but they\'re likely to\nbe different names, so this might work less effectively for datasets\nwhere extended characters play a substantial differentiation role.'}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"n-gram-fingerprint",children:"N-Gram Fingerprint"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.a,{href:"http://en.wikipedia.org/wiki/N-gram",children:"n-gram"})," fingerprint method does the following:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"change all characters to their lowercase representation"}),"\n",(0,i.jsx)(n.li,{children:"remove all punctuation, whitespace, and control characters"}),"\n",(0,i.jsx)(n.li,{children:"obtain all the string n-grams"}),"\n",(0,i.jsx)(n.li,{children:"sort the n-grams and remove duplicates"}),"\n",(0,i.jsx)(n.li,{children:"join the sorted n-grams back together"}),"\n",(0,i.jsx)(n.li,{children:"normalize extended western characters to their ASCII representation"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:'So, for example, the 2-gram fingerprint of "Paris" is "arispari" and the\n1-gram fingerprint is "aiprs".'}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"http://github.com/OpenRefine/OpenRefine/blob/master/main/src/com/google/refine/clustering/binning/NGramFingerprintKeyer.java",children:"Check the code"}),"\nif you're curious about the details."]}),"\n",(0,i.jsx)(n.p,{children:"Why is this useful? In practice, using big values for n-grams doesn't\nyield any advantage over the previous fingerprint method, but using\n2-grams and 1-grams, while yielding many false positives, can find\nclusters that the previous method didn't find even with strings that\nhave small differences, with a very small performance price."}),"\n",(0,i.jsx)(n.p,{children:'For example "Krzysztof", "Kryzysztof", and "Krzystof" have different\nlengths and different regular fingerprints, but share the same 1-gram\nfingerprint because they use the same letters.'}),"\n",(0,i.jsx)(n.h3,{id:"phonetic-fingerprint",children:"Phonetic Fingerprint"}),"\n",(0,i.jsx)(n.p,{children:"Phonetic fingerprinting is a way to transform tokens into the way they are\npronounced. This is useful to spot errors that are due to people\nmisunderstanding or not knowing the spelling of a word after only\nhearing it. The idea is that similar-sounding words will end up\nsharing the same key and thus being binned in the same cluster."}),"\n",(0,i.jsx)(n.p,{children:'For example, "Reuben Gevorkiantz" and "Ruben Gevorkyants" share the same\nphonetic fingerprint for English pronunciation but they have different\nfingerprints for both the regular and n-gram fingerprinting methods\nabove, no matter the size of the n-gram.'}),"\n",(0,i.jsx)(n.p,{children:'OpenRefine supports multiple "Phonetic" algorithms including:'}),"\n",(0,i.jsx)(n.h4,{id:"metaphone3",children:"Metaphone3"}),"\n",(0,i.jsx)(n.p,{children:"Metaphone3 improves phonetic encoding for not just words in the English Language but also non-English words, first names, and last names common in the United States."}),"\n",(0,i.jsx)(n.p,{children:"The 'approximate' aspect of the encoding for OpenRefine (version 2.1.3) is implemented according to the following rules:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"All vowels are encoded to the same value - 'A'."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["If the parameter ",(0,i.jsx)(n.em,{children:"encodeVowels"})," is set to false, only ",(0,i.jsx)(n.em,{children:"initial"})," vowels will be encoded at all."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:["If ",(0,i.jsx)(n.em,{children:"encodeVowels"})," is set to true, 'A' will be encoded at all places in the word that any vowels are normally pronounced."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"'W', as well as 'Y', are treated as vowels. Although there are differences in their pronunciation in different circumstances that lead to their being classified as vowels under some circumstances and as consonants in others, for the 'fuzziness' component of the Soundex and Metaphone family of algorithms they will be always be treated here as vowels."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Voiced and un-voiced consonant pairs are mapped to the same encoded value. That is:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"'D' and 'T' -> 'T'"}),"\n",(0,i.jsx)(n.li,{children:"'B' and 'P' -> 'P'"}),"\n",(0,i.jsx)(n.li,{children:"'G' and 'K' -> 'K'"}),"\n",(0,i.jsx)(n.li,{children:"'Z' and 'S' -> 'S'"}),"\n",(0,i.jsx)(n.li,{children:"'V' and 'F' -> 'F'"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"In addition to the above voiced/unvoiced rules, 'CH' and 'SH' -> 'X', where 'X' represents the \"-SH-\" and \"-CH-\" sounds in Metaphone 3 encoding."}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:"Also, the sound that is spelled as \"TH\" in English is encoded to '0' (zero)."}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"cologne-phonetics",children:"Cologne Phonetics"}),"\n",(0,i.jsxs)(n.p,{children:["Cologne Phonetics, also called K\xf6lner Phonetik, is a phonetic algorithm that assigns a sequence of digits (called the ",(0,i.jsx)(n.strong,{children:"phonetic code"}),") to words."]}),"\n",(0,i.jsx)(n.p,{children:"Unlike Metaphone3, Cologne Phonetics is optimized for the German language."}),"\n",(0,i.jsxs)(n.p,{children:["The process of encoding words using Cologne phonetics can be broken down to the following steps:\n",(0,i.jsx)(n.strong,{children:"Step 1:"})]}),"\n",(0,i.jsx)(n.p,{children:"The encoding process is as follows:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["The word is preprocessed. That is,","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"conversion to upper case"}),"\n",(0,i.jsx)(n.li,{children:"transcription of germanic umlauts"}),"\n",(0,i.jsx)(n.li,{children:"removal of non-alphabetical characters"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"-The letters are then replaced by their phonetic codes according to the following table:"}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Letter"}),(0,i.jsx)("th",{children:"Context"}),(0,i.jsx)("th",{children:"Code"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"A, E, I, O, U"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{children:"0"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"H"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{children:"-"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"B"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{rowspan:"2",children:"1"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"P"}),(0,i.jsx)("td",{children:"not before H"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"D, T"}),(0,i.jsx)("td",{children:"not before C, S, Z"}),(0,i.jsx)("td",{children:"2"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"F, V, W"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{rowspan:"2",children:"3"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"P"}),(0,i.jsx)("td",{children:"before H"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"G, K, Q"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{rowspan:"3",children:"4"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{rowspan:"2",children:"C"}),(0,i.jsx)("td",{children:"at onset before A, H, K, L, O, Q, R, U, X"})]}),(0,i.jsx)("tr",{children:(0,i.jsx)("td",{children:"before A, H, K, O, Q, U, X except after S, Z"})}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"X"}),(0,i.jsx)("td",{children:"not after C, K, Q"}),(0,i.jsx)("td",{children:"48"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"L"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{children:"5"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"M, N"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{children:"6"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"R"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{children:"7"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"S, Z"}),(0,i.jsx)("td",{}),(0,i.jsx)("td",{rowspan:"6",children:"8"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{rowspan:"3",children:"C"}),(0,i.jsx)("td",{children:"after S, Z"})]}),(0,i.jsx)("tr",{children:(0,i.jsx)("td",{children:"at onset except before A, H, K, L, O, Q, R, U, X"})}),(0,i.jsx)("tr",{children:(0,i.jsx)("td",{children:"not before A, H, K, O, Q, U, X"})}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"D, T"}),(0,i.jsx)("td",{children:"before C, S, Z"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:"X"}),(0,i.jsx)("td",{children:"after C, K, Q"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"For example"}),'\nFollowing the rules stated above, the phrase "Good morning" in German could be encoded as:']}),"\n",(0,i.jsx)(n.p,{children:"Guten Morgen -> GUTENMORGEN -> 40206607406"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Step 2:"})}),"\n",(0,i.jsx)(n.p,{children:"Any consecutive duplicate digit is removed"}),"\n",(0,i.jsxs)(n.p,{children:["4020",(0,i.jsx)(n.strong,{children:"66"}),"07406 -> 4020607406"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Step 3:"})}),"\n",(0,i.jsxs)(n.p,{children:['Removal of all codes "0" ',(0,i.jsx)(n.strong,{children:"except"})," at the beginning."]}),"\n",(0,i.jsxs)(n.p,{children:["4",(0,i.jsx)(n.strong,{children:"0"}),"2",(0,i.jsx)(n.strong,{children:"0"}),"6",(0,i.jsx)(n.strong,{children:"0"}),"74",(0,i.jsx)(n.strong,{children:"0"}),"6 -> 426746"]}),"\n",(0,i.jsx)(n.p,{children:"Hence, by the Cologne phonetic, Guteng Morgen is encoded as 426746"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note"}),' that two or more identical consecutive digits can occur if they occur after removing the "0" digits.']}),"\n",(0,i.jsx)(n.h4,{id:"daitch-moktoff",children:"Daitch-Moktoff"}),"\n",(0,i.jsx)(n.p,{children:"The Daitch-Moktoff phonetic algorithm was created by  Randy Daitch and Gary Mokotoff of the Jewish Genealogical Society (New York), hence its name."}),"\n",(0,i.jsxs)(n.p,{children:["It is a refinement of the ",(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Soundex",children:"Soundex"})," algorithms designed to allow greater accuracy in matching Slavic and Yiddish surnames with similar pronunciation but differences in spelling."]}),"\n",(0,i.jsx)(n.p,{children:"The rules for converting surnames into D-M codes are as follows:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Names are coded to six digits, each digit representing a sound listed in the ",(0,i.jsx)(n.a,{href:"https://www.jewishgen.org/infofiles/soundex.html",children:"coding chart"})]}),"\n",(0,i.jsx)(n.li,{children:"When a name lacks enough coded sounds for six digits, use zeros to fill to six digits."}),"\n",(0,i.jsx)(n.li,{children:"The letters A, E, I, O, U, J, and Y are always coded at the beginning of a name as in Alice.  In any other situation, they are ignored except when two of them form a pair and the pair comes before a vowel, as in Isaiah but not Freud."}),"\n",(0,i.jsx)(n.li,{children:"The letter H is coded at the beginning of a name, as in Haber, or preceding a vowel, as in Manheim, otherwise, it is not coded."}),"\n",(0,i.jsx)(n.li,{children:"When adjacent sounds can combine to form a larger sound, they are given the code number of the larger sound.  Mintz is not coded MIN-T-Z but MIN-TZ."}),"\n",(0,i.jsx)(n.li,{children:"When adjacent letters have the same code number, they are coded as one sound, as in TOPF, which is not coded TO-P-F but TO-PF.  Exceptions to this rule are the letter combinations MN and NM, whose letters are coded separately, as in Kleinman."}),"\n",(0,i.jsx)(n.li,{children:'When a surname consists of more than one word, it is coded as if one word, such as "Ben Aron", is treated as "Benaron".'}),"\n",(0,i.jsx)(n.li,{children:"Several letters and letter combinations pose the problem that they may sound in one of two ways.  The letter and letter combinations CH, CK, C, J, and RS are assigned two possible code numbers."}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"beider-morse",children:"Beider-Morse"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.a,{href:"https://stevemorse.org/phonetics/bmpm.htm",children:"Beider-Morse Phonetic Matching"})," (BMPM) is a very intelligent algorithm, compared to ",(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Metaphone",children:"Metaphone"}),", whose purpose is to match names that are phonetically equivalent to the expected name. However,  unlike ",(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/Soundex",children:"soundex"})," methods, the \u201csounds-alike\u201d test is based not only on the spelling but on the linguistic properties of various languages."]}),"\n",(0,i.jsx)(n.p,{children:"The steps for comparison are as follows:"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step 1:"})," Determines the language from the spelling of the name"]}),"\n",(0,i.jsx)(n.p,{children:"The spelling of a name can include some letters or letter combinations that allow the language to be determined. Some examples are:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'"tsch", final "mann" and "witz" are specifically German'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'final and initial "cs" and "zs" are necessarily Hungarian'}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:'"cz", "cy", initial "rz" and "wl", final "cki", letters "\u015b", "\u0142" and "\u017c" can be only Polish'}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step 2:"})," Applies phonetic rules to identify the language and translates the name into phonetic alphabets"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step 3:"})," Calculating the Approximate Phonetic Value"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step 4:"})," Calculating the Hebrew Phonetic Value"]}),"\n",(0,i.jsxs)(n.p,{children:["The entire process is described in detail in this ",(0,i.jsx)(n.a,{href:"https://stevemorse.org/phonetics/bmpm.htm",children:"document"})]}),"\n",(0,i.jsx)(n.h2,{id:"nearest-neighbor-methods",children:"Nearest Neighbor Methods"}),"\n",(0,i.jsx)(n.p,{children:"While key collisions methods are very fast, they tend to be either too\nstrict or too lax with no way to fine-tune how much difference between\nstrings we are willing to tolerate."}),"\n",(0,i.jsxs)(n.p,{children:["The\n",(0,i.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm",children:"Nearest Neighbor"}),"\nmethods (also known as kNN), on the other hand, provide a parameter (the\nradius or ",(0,i.jsx)(n.code,{children:"k"}),") which represents a distance threshold: any pair of\nstrings that are closer than a certain value will be binned together."]}),"\n",(0,i.jsxs)(n.p,{children:["Unfortunately, given n strings, there are ",(0,i.jsx)(n.code,{children:"n(n-1)/2"})," pairs of strings\n(and relative distances) that need to be compared and this turns out to\nbe too slow even for small datasets (a dataset with 3000 rows require\n4.5 million distance calculations!)."]}),"\n",(0,i.jsx)(n.p,{children:"We have tried various methods to speed up this process but the one that\nworks the best is called 'blocking' and is, in fact, a hybrid between\nkey collision and kNN. This works by performing a first pass over the\nsequence of strings to evaluate and obtain 'blocks' in which all strings\nshare a substring of a given 'blocking size' (which defaults to 6 chars\nin OpenRefine)."}),"\n",(0,i.jsxs)(n.p,{children:["Blocking doesn't change the computational complexity of the kNN method\nbut drastically reduces the number of strings that will be matched\nagainst one another (because strings are matched only inside the block\nthat contains them). So instead of ",(0,i.jsx)(n.code,{children:"n(n-1)/2"})," we now have ",(0,i.jsx)(n.code,{children:"nm(m-1)/2"}),"\nbut ",(0,i.jsx)(n.code,{children:"n"})," is the number of blocks and ",(0,i.jsx)(n.code,{children:"m"})," is the average size of the\nblock. In practice, this turns out to be dramatically faster because the\nblock size is comparable to the number of strings and the blocks are\nnormally much smaller. For example, for 3000 strings, you can have a\nthousand blocks composed of 10 strings each, which requires 45k\ndistances to calculate instead of 4.5M!"]}),"\n",(0,i.jsx)(n.p,{children:"If you're not in a hurry, OpenRefine lets you select the size of the\nblocking substring and you can lower it down to 2 or 1 and make sure\nthat blocking is not hiding a potential pair from your search...\nalthough in practice, anything lower than 3 normally turns out to be a\nwaste of time."}),"\n",(0,i.jsx)(n.p,{children:"All the above is shared between all the kNN methods, the difference of\noperation lies in the method used to evaluate the distance between the\ntwo strings."}),"\n",(0,i.jsx)(n.p,{children:"For kNN distances, we found that blocking with less than 3 or 4 chars explodes the amount of time clustering takes and yields very few new valuable results, but your mileage may vary."}),"\n",(0,i.jsx)(n.h3,{id:"levenshtein-distance",children:"Levenshtein Distance"}),"\n",(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.a,{href:"http://en.wikipedia.org/wiki/Levenshtein_distance",children:"Levenshtein"}),"\ndistance (also known as \"edit distance\") is probably the simplest and\nmost intuitive distance function between strings and is often still very\neffective due to its general applicability. It measures the minimal number of ' edit operations ' that are required to\nchange one string into the other."]}),"\n",(0,i.jsxs)(n.p,{children:["It's worth noting that there are many flavors of edit-based distance\nfunctions (say, the\n",(0,i.jsx)(n.a,{href:"http://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance",children:"Damerau-Levenshtein distance"}),",\nwhich considers 'transposition' as a single operation) but in practice,\nfor clustering purposes, they tend to be equally functional (as long as\nthe user has control over the distance threshold)."]}),"\n",(0,i.jsx)(n.h3,{id:"ppm",children:"PPM"}),"\n",(0,i.jsxs)(n.p,{children:["This distance is an implementation of\n",(0,i.jsx)(n.a,{href:"http://arxiv.org/abs/cs/0111054",children:"a seminal paper"})," about the use of\nthe\n",(0,i.jsx)(n.a,{href:"http://en.wikipedia.org/wiki/Kolmogorov_complexity",children:"Kolmogorov complexity"}),"\nto estimate 'similarity' between strings and has been widely applied to\nthe comparison of strings originating from DNA sequencing."]}),"\n",(0,i.jsx)(n.p,{children:"The idea is that because text compressors work by estimating the\ninformation content of a string, if two strings A and B are identical,\ncompressing A or compressing A+B (concatenating the strings) should\nyield very little difference (ideally, a single extra bit to indicate\nthe presence of the redundant information). On the other hand, if A and\nB are very different, compressing A and compressing A+B should yield\ndramatic differences in length."}),"\n",(0,i.jsx)(n.p,{children:"OpenRefine uses a normalized version of the algorithm, where the\ndistance between A and B is given by"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"   d(A,B) = comp(A+B) + comp(B+A) / (comp(A+A) + comp(B+B));\n"})}),"\n",(0,i.jsxs)(n.p,{children:["where ",(0,i.jsx)(n.code,{children:"comp(s)"})," is the length of bytes of the compressed sequence of the\nstring ",(0,i.jsx)(n.code,{children:"s"})," and ",(0,i.jsx)(n.code,{children:"+"})," is the append operator. This is used to account for\ndeviation in the optimality of the given compressors."]}),"\n",(0,i.jsx)(n.p,{children:"While many different compressors can be used, the closer to Kolmogorov\noptimality they are (meaning, the better they encode) the more effective\ntheir result."}),"\n",(0,i.jsxs)(n.p,{children:["For this reason, we have used\n",(0,i.jsx)(n.a,{href:"http://en.wikipedia.org/wiki/Prediction_by_Partial_Matching",children:"Prediction by Partial Matching"}),"\nas the compressor algorithm as it is one of the most effective\ncompression algorithms for text and works by performing statistical\nanalysis and predicting what character will come next in a string."]}),"\n",(0,i.jsx)(n.p,{children:"In practice, this method is very lax even for small radius values and\ntends to generate many false positives, but because it operates at a\nsub-character level it is capable of finding substructures that are not\neasily identifiable by distances that work at the character level. So it\nshould be used as a 'last resort' clustering method; that's why it is\nlisted last here despite its phenomenal efficacy in other realms."}),"\n",(0,i.jsx)(n.p,{children:"It is also important to note that in practice similar distances are\nmore effective on longer strings than on shorter ones; this is mostly an\nartifact of the need for the statistical compressors to 'warm up' and\ngather enough statistics to start performing well."}),"\n",(0,i.jsx)(n.h1,{id:"cluster-new-value-suggestions",children:"Cluster New Value Suggestions"}),"\n",(0,i.jsxs)(n.p,{children:["For each cluster identified, one value is chosen as the initial 'New\nCell Value' to use as the common value for all values in the cluster.\nThe value chosen is the first value in the Cluster: see the\n",(0,i.jsx)(n.code,{children:"ClusteringDialog.prototype.\\_updateData"})," function in\n",(0,i.jsx)(n.a,{href:"https://github.com/OpenRefine/OpenRefine/blob/master/main/webapp/modules/core/scripts/dialogs/clustering-dialog.js",children:"/main/webapp/modules/core/scripts/dialogs/clustering-dialog.js"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"The first value in the Cluster is determined by two steps:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"a) The order of the items in the Cluster as the Cluster is built"}),"\n",(0,i.jsx)(n.li,{children:"b) The order of the items in the Cluster after sorting by the count\nof the occurrences of each value"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["(a) is achieved via a Collections.sort - which is ",(0,i.jsx)(n.a,{href:"https://docs.oracle.com/javase/7/docs/api/java/util/Collections.html#sort(java.util.List,%20java.util.Comparator)",children:'"guaranteed to be stable: equal elements will not be reordered as a result of the sort."'}),(0,i.jsx)("br",{}),"\n(b) is achieved by different methods depending on whether you are doing a Nearest Neighbour or Key Collisions (aka Binning) cluster"]}),"\n",(0,i.jsxs)(n.p,{children:["If you are using Key Collision/Binning then the Cluster is created using a TreeMap which by default ",(0,i.jsx)(n.a,{href:"https://docs.oracle.com/javase/7/docs/api/java/util/TreeMap.html",children:'"is sorted according to the natural\nordering of its keys"'}),".",(0,i.jsx)("br",{}),"\nThe key is the string in the cell - so that means it will sort by the natural ordering of the strings in the cluster - which means that it\nuses a ",(0,i.jsx)(n.a,{href:"http://docs.oracle.com/javase/7/docs/api/java/lang/String.html#compareTo%28java.lang.String%29",children:"'lexicographical' order"})," - basically based on the Unicode values in the string"]}),"\n",(0,i.jsx)(n.p,{children:"If you are using the Nearest Neighbour sort the Cluster is created in a different way which is (as yet) undocumented. Testing indicates that it may be something like reverse natural ordering."}),"\n",(0,i.jsx)(n.h1,{id:"contribute",children:"Contribute"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"We've been focusing mostly on English content or data ported to\nEnglish. We know some of the methods might be biased towards it but\nwe're willing to introduce more methods\nonce the OpenRefine community gathers more insights into these\nproblems;"}),"\n",(0,i.jsx)(n.li,{children:"OpenRefine's internals support a lot more methods but we have turned\noff many of them because they don't seem to have much practical\nadvantage over the ones described here. If you think that\nOpenRefine should use other methods, feel free to suggest them to us\nbecause we might have overlooked them."}),"\n"]}),"\n",(0,i.jsx)(n.h1,{id:"suggested-reading",children:"Suggested Reading"}),"\n",(0,i.jsxs)(n.p,{children:["A lot of the code that OpenRefine uses for clustering originates from\nresearch done by the ",(0,i.jsx)(n.a,{href:"http://simile.mit.edu/",children:"SIMILE Project"})," at MIT\nwhich later\n",(0,i.jsx)(n.a,{href:"http://code.google.com/p/simile-vicino/",children:"graduated as the Vicino project"}),"\n('vicino', pronounced \"vitch-ee-no\", means 'near' in Italian)."]}),"\n",(0,i.jsxs)(n.p,{children:["For more information on clustering methods and related research we\nsuggest you look at the\n",(0,i.jsx)(n.a,{href:"http://code.google.com/p/simile-vicino/source/browse/#svn/trunk/papers",children:"bibliography of the Vicino project"}),"."]})]})}function c(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},69018:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>o});var i=t(47768);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);